{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Some Installs"
      ],
      "metadata": {
        "id": "oR2Gi2-9aaD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  -q -U langgraph \"langchain[openai]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDQQT3U3ZXyN",
        "outputId": "edb74376-cbba-4840-aca0-b13d8fc3fede"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.9/43.9 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q gradio"
      ],
      "metadata": {
        "id": "v873W4HzaG_O"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install -q langchain_community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgSkU4XbaKxg",
        "outputId": "e1f1f0ea-784a-4ca4-b694-9cadd3daf0df"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/2.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/2.5 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "iPfM5a5GaeLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from typing import Annotated, TypedDict, List, Dict, Any, Optional\n",
        "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.agent_toolkits import PlayWrightBrowserToolkit\n",
        "from langchain_community.tools.playwright.utils import create_async_playwright_browser\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langgraph.prebuilt import ToolNode,tools_condition\n",
        "from langgraph.graph.message import add_messages\n",
        "from pydantic import BaseModel, Field\n",
        "from IPython.display import Image, display\n",
        "import gradio as gr\n",
        "import uuid\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "from langchain.agents import tool,Tool"
      ],
      "metadata": {
        "id": "67gmWPQ-ZWuQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Let's Start"
      ],
      "metadata": {
        "id": "I2CUR5tAaix6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "E5QxHi9VYuf7"
      },
      "outputs": [],
      "source": [
        "# LangSmith\n",
        "f=open(\"/content/LangSmith API.txt\",\"r\")\n",
        "smith_api_key=f.read()\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = smith_api_key\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"My-Research-Assistant\"\n",
        "\n",
        "# OpenAI Key\n",
        "f=open(\"/content/OpenAIKey.txt\",\"r\")\n",
        "api_key=f.read()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* The LLM I Will Use"
      ],
      "metadata": {
        "id": "tfiDukAYa6wS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatOpenAI(\n",
        "    model_name=\"x-ai/grok-4-fast:free\",\n",
        "    openai_api_key=api_key,\n",
        "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
        "    temperature=0.0)"
      ],
      "metadata": {
        "id": "aLGIT2KAa5v5"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "* I will use one node in order to create the Researchers"
      ],
      "metadata": {
        "id": "0D73ohLG2WyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Researchers(BaseModel):\n",
        "  name: str= Field(description='The name of the researcher')\n",
        "  role: str= Field(description='The role of the researcher in the context of the topic')\n",
        "  research_interests: str= Field(description='The research interests of the researcher')\n",
        "  research_field: str= Field(description='The research field of the researcher')\n",
        "  @property\n",
        "  def description(self)->str:\n",
        "    return f\"Name: {self.name}\\nRole: {self.role}\\nResearch Interests: {self.research_interests}\\nResearch Field: {self.research_field}\""
      ],
      "metadata": {
        "id": "sBbJmryNcPTT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Res_List(BaseModel):\n",
        "  re_list: List[Researchers]= Field(description='The list of researchers with role, name, research interests and research field')"
      ],
      "metadata": {
        "id": "2O1K6tZd38cE"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Re_State(TypedDict):\n",
        "  re_list: List[Researchers]\n",
        "  topic: str\n",
        "  max_researchers:int\n",
        "\n"
      ],
      "metadata": {
        "id": "7o-Fsx2q4Zlc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_researchers(state:Re_State)->Res_List:\n",
        "  llm_with_structure=llm.with_structured_output(Res_List)\n",
        "\n",
        "  prompt=ChatPromptTemplate.from_messages([\n",
        "      ('system',\"\"\"You are tasked with creating a set of AI researchers.\n",
        "      1. First read carefully the the topic:\\n {topic}\n",
        "      2. Determine the most interesting themes based upon documents or feedback above.\n",
        "      3. Pick the top {max_researchers} themes.\"\"\"),\n",
        "      ('user',\" Generate the set of analyst\")])"
      ],
      "metadata": {
        "id": "Y3cFBzvf5XHh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}